{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":89760,"databundleVersionId":10486094,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":3067.588899,"end_time":"2024-12-14T10:21:33.420617","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-14T09:30:25.831718","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e5555d02","cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom os.path import join\nfrom torchvision.transforms import v2\nfrom torch import optim, nn\nfrom torchmetrics.image import PeakSignalNoiseRatio\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-12-15T12:38:14.849534Z","iopub.execute_input":"2024-12-15T12:38:14.849795Z","iopub.status.idle":"2024-12-15T12:38:21.594193Z","shell.execute_reply.started":"2024-12-15T12:38:14.849761Z","shell.execute_reply":"2024-12-15T12:38:21.593260Z"},"papermill":{"duration":12.966379,"end_time":"2024-12-14T09:30:42.322419","exception":false,"start_time":"2024-12-14T09:30:29.356040","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"id":"494ff368","cell_type":"code","source":"image_transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n\nlabel_transform=  v2.Compose([v2.ToImage(),  v2.ToDtype(torch.float32, scale=True)])","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:21.596045Z","iopub.execute_input":"2024-12-15T12:38:21.596652Z","iopub.status.idle":"2024-12-15T12:38:21.602656Z","shell.execute_reply.started":"2024-12-15T12:38:21.596617Z","shell.execute_reply":"2024-12-15T12:38:21.601337Z"},"papermill":{"duration":0.010336,"end_time":"2024-12-14T09:30:42.336614","exception":false,"start_time":"2024-12-14T09:30:42.326278","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"id":"108f58fd","cell_type":"code","source":"class ImageEnhancementDataset(Dataset):\n    def __init__(self, image_folder, label_folder, input_transform=None, label_transform=None):\n        self.image_folder = image_folder\n        self.label_folder = label_folder\n        self.input_transform = input_transform\n        self.label_transform = label_transform\n\n        # Ensure both folders have the same number of files\n        self.image_filenames = sorted(os.listdir(image_folder))\n        self.label_filenames = sorted(os.listdir(label_folder))\n\n        assert len(self.image_filenames) == len(self.label_filenames), \"Mismatch between image and label counts.\"\n\n    def __len__(self):\n        return len(self.image_filenames)\n\n    def __getitem__(self, idx):\n        # Load the input and label images\n        image_path = os.path.join(self.image_folder, self.image_filenames[idx])\n        label_path = os.path.join(self.label_folder, self.label_filenames[idx])\n\n        image = Image.open(image_path) #.convert(\"RGB\")\n        label = Image.open(label_path) #.convert(\"RGB\")\n\n        # Ensure label size is 4x the input size\n        input_size = image.size  # (width, height)\n        label_size = label.size  # (width, height)\n        expected_label_size = (input_size[0] * 4, input_size[1] * 4)\n\n        assert label_size == expected_label_size, (\n            f\"Label size {label_size} does not match the expected size {expected_label_size} for input {input_size}.\"\n        )\n\n        # Apply transformations if provided\n        if self.input_transform:\n            image = self.input_transform(image)\n\n        if self.label_transform:\n            label = self.label_transform(label)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:21.604341Z","iopub.execute_input":"2024-12-15T12:38:21.604801Z","iopub.status.idle":"2024-12-15T12:38:21.616680Z","shell.execute_reply.started":"2024-12-15T12:38:21.604758Z","shell.execute_reply":"2024-12-15T12:38:21.616021Z"},"papermill":{"duration":0.014111,"end_time":"2024-12-14T09:30:42.354132","exception":false,"start_time":"2024-12-14T09:30:42.340021","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"a531810e","cell_type":"code","source":"root_dir = \"/kaggle/input/enhance-the-dark-world/archive\"\ntrain_dir = join(root_dir,\"train\")\nval_dir = join(root_dir,\"val\")\ntest_dir = join(root_dir,\"test\")","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:21.618364Z","iopub.execute_input":"2024-12-15T12:38:21.618650Z","iopub.status.idle":"2024-12-15T12:38:21.628614Z","shell.execute_reply.started":"2024-12-15T12:38:21.618621Z","shell.execute_reply":"2024-12-15T12:38:21.628036Z"},"papermill":{"duration":0.009282,"end_time":"2024-12-14T09:30:42.366690","exception":false,"start_time":"2024-12-14T09:30:42.357408","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"354cfb03","cell_type":"code","source":"train_dataset = ImageEnhancementDataset(\n    join(train_dir,\"train\"), join(train_dir,\"gt\"),input_transform=image_transform,label_transform=label_transform\n)\n\nval_dataset = ImageEnhancementDataset(\n    join(val_dir,\"val\"), join(val_dir, \"gt\"), input_transform=image_transform, label_transform=label_transform\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:21.629605Z","iopub.execute_input":"2024-12-15T12:38:21.629931Z","iopub.status.idle":"2024-12-15T12:38:21.673491Z","shell.execute_reply.started":"2024-12-15T12:38:21.629907Z","shell.execute_reply":"2024-12-15T12:38:21.672756Z"},"papermill":{"duration":0.063634,"end_time":"2024-12-14T09:30:42.433515","exception":false,"start_time":"2024-12-14T09:30:42.369881","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"4d0a3a1a","cell_type":"code","source":"batch_size = 4\n\ntrain_loader = DataLoader(train_dataset,batch_size = batch_size, shuffle = True, num_workers = 4)\nval_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = 4)\n","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:21.674358Z","iopub.execute_input":"2024-12-15T12:38:21.674597Z","iopub.status.idle":"2024-12-15T12:38:21.678682Z","shell.execute_reply.started":"2024-12-15T12:38:21.674574Z","shell.execute_reply":"2024-12-15T12:38:21.677898Z"},"papermill":{"duration":0.010509,"end_time":"2024-12-14T09:30:42.447279","exception":false,"start_time":"2024-12-14T09:30:42.436770","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"id":"c696cb8d","cell_type":"code","source":"for images,labels in train_loader:\n    print(images.size())\n    print(labels.size())\n    break","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:21.679881Z","iopub.execute_input":"2024-12-15T12:38:21.680487Z","iopub.status.idle":"2024-12-15T12:38:22.803608Z","shell.execute_reply.started":"2024-12-15T12:38:21.680449Z","shell.execute_reply":"2024-12-15T12:38:22.802635Z"},"papermill":{"duration":1.380419,"end_time":"2024-12-14T09:30:43.830888","exception":false,"start_time":"2024-12-14T09:30:42.450469","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"torch.Size([4, 3, 160, 256])\ntorch.Size([4, 3, 640, 1024])\n","output_type":"stream"}],"execution_count":7},{"id":"1857bc55","cell_type":"code","source":"class Conv2d1x1(nn.Module):\n    def __init__(self, input_channels: int, reduction_factor: int = 1, out_channels: int = None):\n        super().__init__()\n\n        if out_channels is None:\n            out_channels = input_channels // reduction_factor\n\n        self.out_channels = out_channels\n\n        # define the 1x1 convolution layer\n        self.conv = nn.Conv2d(in_channels=input_channels, out_channels=out_channels, kernel_size=(1, 1))\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass DepthwiseConv2d(nn.Module):\n    def __init__(self, input_channels: int, kernel_size: int):\n        super().__init__()\n\n        padding_size = kernel_size // 2\n\n        self.conv = nn.Conv2d(in_channels=input_channels, out_channels=input_channels,\n                              kernel_size=(kernel_size, kernel_size), groups=input_channels,\n                              padding=(padding_size, padding_size))\n\n    def forward(self, input_tensor):\n        return self.conv(input_tensor)\n\n\nclass PointwiseConv2d(nn.Module):\n    def __init__(self, input_channels: int, out_channels: int = None):\n        super().__init__()\n\n        if out_channels is None:\n            out_channels = input_channels\n\n        self.conv = Conv2d1x1(input_channels=input_channels, out_channels=out_channels)\n\n    def forward(self, input_tensor):\n        return self.conv(input_tensor)\n\n\nclass TwoFoldAttentionModule(nn.Module):\n    class ChannelUnit(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n\n            self.in_channels = input_channels\n\n            # we define a global average pooling layer that extracts first-order statistics of features\n            self.global_avg_pooling = nn.AdaptiveAvgPool2d(output_size=1)\n\n            # input tensor\n            conv_1x1_input_channels = input_channels // 2\n            self.conv1x1_1 = Conv2d1x1(input_channels=conv_1x1_input_channels)\n            self.conv1x1_2 = Conv2d1x1(input_channels=conv_1x1_input_channels)\n\n        def forward(self, input_tensor):\n            first_order_statistics = self.global_avg_pooling(input_tensor)  # output_size = (N, in_channels, 1, 1)\n            half_channels = self.in_channels // 2\n            first_half_input, second_half_input = torch.split(first_order_statistics,\n                                                              split_size_or_sections=half_channels, dim=1)\n            first_half_output = self.conv1x1_1(first_half_input)  # output_size = (N, in_channels/2, 1, 1)\n            second_half_output = self.conv1x1_2(second_half_input)  # output_size = (N, in_channels/2, 1, 1)\n            concatenated_halves = torch.cat((first_half_output, second_half_output), dim=1)\n            output = torch.mul(concatenated_halves, input_tensor)  # output_size = (N, in_channels, 1, 1)\n            return output\n\n    class PositionalUnit(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n            self.avg_pooling = nn.AvgPool2d(kernel_size=(7, 7))\n            self.max_pooling = nn.MaxPool2d(kernel_size=(7, 7))\n            kernel_size = 7\n            padding_size = kernel_size // 2\n            self.conv2d_1 = nn.Conv2d(in_channels=input_channels * 2, out_channels=input_channels,\n                                      kernel_size=(kernel_size, kernel_size),\n                                      padding=(padding_size, padding_size))\n\n        def forward(self, input_tensor):\n            height = input_tensor.size()[2]\n            width = input_tensor.size()[3]\n            output_max_pool = self.max_pooling(input_tensor)\n            output_avg_pool = self.avg_pooling(input_tensor)\n            output_pool = torch.cat((output_max_pool, output_avg_pool), dim=1)\n            upsampled_out = F.interpolate(output_pool, size=(height, width), mode=\"bilinear\", align_corners=False)\n            output = self.conv2d_1(upsampled_out)\n            return output\n\n    def __init__(self, input_channels: int):\n        super().__init__()\n        self.conv1x1_1 = Conv2d1x1(input_channels=input_channels, reduction_factor=16)\n        self.ca_unit = self.ChannelUnit(input_channels=self.conv1x1_1.out_channels)\n        self.pos_unit = self.PositionalUnit(input_channels=self.conv1x1_1.out_channels)\n        self.conv1x1_2 = Conv2d1x1(input_channels=self.conv1x1_1.out_channels, out_channels=input_channels)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_tensor):\n        conv_1x1_1_out = self.conv1x1_1(input_tensor)\n        ca_unit_out = self.ca_unit(conv_1x1_1_out)\n        pos_unit_out = self.pos_unit(conv_1x1_1_out)\n        sum_output = torch.add(ca_unit_out, pos_unit_out)\n        conv_1x1_2_out = self.conv1x1_2(sum_output)\n        sigmoid_out = self.sigmoid(conv_1x1_2_out)\n        output = torch.mul(input_tensor, sigmoid_out)\n        return output\n\n\nclass AdaptiveResidualBlock(nn.Module):\n    class BottleneckPath(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n\n            self.dw_conv_1 = DepthwiseConv2d(input_channels=input_channels, kernel_size=3)\n\n            self.pw_conv_1 = PointwiseConv2d(input_channels=input_channels)\n            self.lrelu_1 = nn.LeakyReLU()\n\n            self.dw_conv_2 = DepthwiseConv2d(input_channels=input_channels, kernel_size=3)\n\n            self.tfam = TwoFoldAttentionModule(input_channels=input_channels)\n            self.lrelu_2 = nn.LeakyReLU()\n            self.pw_conv_2 = PointwiseConv2d(input_channels=input_channels)\n\n        def forward(self, input_tensor):\n            dw_conv_1_out = self.dw_conv_1(input_tensor)\n            pw_conv_1_out = self.pw_conv_1(dw_conv_1_out)\n            lrelu_1_out = self.lrelu_1(pw_conv_1_out)\n\n            dw_conv_2_out = self.dw_conv_2(lrelu_1_out)\n            tfam_out = self.tfam(dw_conv_2_out)\n            lrelu_2_out = self.lrelu_2(tfam_out)\n            output = self.pw_conv_2(lrelu_2_out)\n            return output\n\n    class AdaptivePath(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n\n            self.global_avg_pooling = nn.AdaptiveAvgPool2d(output_size=1)\n\n            self.pw_conv = PointwiseConv2d(input_channels=input_channels)\n\n        def forward(self, input_tensor):\n            global_avg_out = self.global_avg_pooling(input_tensor)\n            output = self.pw_conv(global_avg_out)\n            return output\n\n    class ResidualPath(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n            self.dw_conv = DepthwiseConv2d(input_channels=input_channels, kernel_size=3)\n\n        def forward(self, input_tensor):\n            return self.dw_conv(input_tensor)\n\n    def __init__(self, input_channels: int):\n        super().__init__()\n\n        self.bn_path = self.BottleneckPath(input_channels=input_channels)\n\n        self.ad_path = self.AdaptivePath(input_channels=input_channels)\n\n        self.res_path = self.ResidualPath(input_channels=input_channels)\n\n    def forward(self, input_tensor):\n        bn_path_out = self.bn_path(input_tensor)\n\n        sum_bn_input = torch.add(input_tensor, bn_path_out)\n\n        res_path_out = self.res_path(sum_bn_input)\n\n        ad_path_out = self.ad_path(input_tensor)\n\n        output = torch.add(res_path_out, ad_path_out)\n        return output\n\n\nclass ResidualConcatenationBlock(nn.Module):\n    def __init__(self, input_channels: int):\n        super().__init__()\n\n        self.arb = AdaptiveResidualBlock(input_channels=input_channels)\n\n        first_conv_input_channels = input_channels * 2\n        self.conv_1x1_1 = Conv2d1x1(input_channels=first_conv_input_channels, out_channels=input_channels)\n\n        second_conv_input_channels = input_channels * 3\n        self.conv_1x1_2 = Conv2d1x1(input_channels=second_conv_input_channels, out_channels=input_channels)\n\n        third_conv_input_channels = input_channels * 4\n        self.conv_1x1_3 = Conv2d1x1(input_channels=third_conv_input_channels, out_channels=input_channels)\n\n    def forward(self, input_tensor):\n        arb_1_out = self.arb(input_tensor)\n\n        concat_1_out = torch.cat((input_tensor, arb_1_out), dim=1)\n\n        conv_1x1_1_out = self.conv_1x1_1(concat_1_out)\n\n        arb_2_out = self.arb(conv_1x1_1_out)\n\n        concat_2_out = torch.cat((concat_1_out, arb_2_out), dim=1)\n\n        conv_1x1_2_out = self.conv_1x1_2(concat_2_out)\n\n        arb_3_out = self.arb(conv_1x1_2_out)\n\n        concat_3_out = torch.cat((concat_2_out, arb_3_out), dim=1)\n\n        output = self.conv_1x1_3(concat_3_out)\n\n        return output\n\n\nclass ResidualModule(nn.Module):\n    def __init__(self, input_channels: int):\n        super().__init__()\n\n        self.rcb_1 = ResidualConcatenationBlock(input_channels=input_channels)\n\n        first_conv_input_channels = input_channels * 2\n        self.conv_1x1_1 = Conv2d1x1(input_channels=first_conv_input_channels, out_channels=input_channels)\n\n        self.rcb_2 = ResidualConcatenationBlock(input_channels=input_channels)\n\n        second_conv_input_channels = input_channels * 3\n        self.conv_1x1_2 = Conv2d1x1(input_channels=second_conv_input_channels, out_channels=input_channels)\n\n        self.rcb_3 = ResidualConcatenationBlock(input_channels=input_channels)\n\n        third_conv_input_channels = input_channels * 4\n        self.conv_1x1_3 = Conv2d1x1(input_channels=third_conv_input_channels, out_channels=input_channels)\n\n    def forward(self, h_sfe):\n        rcb_1_out = self.rcb_1(h_sfe)\n\n        concat_1_out = torch.cat((h_sfe, rcb_1_out), dim=1)\n\n        conv_1x1_1_out = self.conv_1x1_1(concat_1_out)\n\n        rcb_2_out = self.rcb_2(conv_1x1_1_out)\n\n        concat_2_out = torch.cat((concat_1_out, rcb_2_out), dim=1)\n\n        conv_1x1_2_out = self.conv_1x1_2(concat_2_out)\n\n        rcb_3_out = self.rcb_3(conv_1x1_2_out)\n\n        concat_3_out = torch.cat((concat_2_out, rcb_3_out), dim=1)\n\n        h_rm = self.conv_1x1_3(concat_3_out)\n\n        return h_rm\n\n\nclass FeatureModule(nn.Module):\n    def __init__(self, input_channels: int):\n        super().__init__()\n\n        # define the first layer, which is a TFAM\n        self.tfam = TwoFoldAttentionModule(input_channels=input_channels)\n\n        # define the second layer, which is a 3x3 conv layer\n        kernel_size = 3\n        padding_size = kernel_size // 2\n        self.conv = nn.Conv2d(in_channels=input_channels, out_channels=input_channels,\n                              kernel_size=(kernel_size, kernel_size), padding=padding_size)\n\n    def forward(self, h_rm, h_sfe):\n        # first, we feed the input tensor (h_rm) to the tfam layer\n        tfam_out = self.tfam(h_rm)\n\n        # then, we feed the output of the tfam layer to the convolutional layer\n        h_gfe = self.conv(tfam_out)\n\n        # finally, we compute the element-wise sum between the output of the convolutional layer and the shallow\n        # features\n        h_fm = torch.add(h_gfe, h_sfe)\n\n        return h_fm\n\n\nclass UpNetModule(nn.Module):\n    class Upsample2x(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n\n            kernel_size = 3\n            padding_size = kernel_size // 2\n\n            # define the submodule that produces a feature map upsampled by 2x\n            self.conv = nn.Conv2d(in_channels=input_channels, out_channels=input_channels * 4, kernel_size=(3, 3),\n                                  padding=padding_size)\n            self.pix_shuf = nn.PixelShuffle(upscale_factor=2)\n\n        def forward(self, input_tensor):\n            # feed the input tensor to the conv layer\n            conv_out = self.conv(input_tensor)\n\n            # feed the output of the conv layer to the pixel shuffle layer\n            pix_shuf_out = self.pix_shuf(conv_out)\n\n            return pix_shuf_out\n\n    class Upsample3x(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n\n            kernel_size = 3\n            padding_size = kernel_size // 2\n\n            # define the submodule that produces a feature map upsampled by 3x\n            self.conv = nn.Conv2d(in_channels=input_channels, out_channels=input_channels * 9, kernel_size=(3, 3),\n                                  padding=padding_size)\n            self.pix_shuf = nn.PixelShuffle(upscale_factor=3)\n\n        def forward(self, input_tensor):\n            # feed the input tensor to the conv layer\n            conv_out = self.conv(input_tensor)\n\n            # feed the output of the conv layer to the pixel shuffle layer\n            pix_shuf_out = self.pix_shuf(conv_out)\n\n            return pix_shuf_out\n\n    class Upsample4x(nn.Module):\n        def __init__(self, input_channels: int):\n            super().__init__()\n\n            # define the first submodule that produces a feature map upsampled by 4x\n            self.upsample_4x = nn.Sequential(UpNetModule.Upsample2x(input_channels=input_channels),\n                                             UpNetModule.Upsample2x(input_channels=input_channels))\n\n        def forward(self, input_tensor):\n            # feed the input tensor to the upsampler\n            return self.upsample_4x(input_tensor)\n\n    def __init__(self, input_channels: int):\n        super().__init__()\n\n        # define the submodule that produces a feature map upsampled by 2x\n        self.upsample_2x = self.Upsample2x(input_channels=input_channels)\n\n        # define the submodule that produces a feature map upsampled by 3x\n        self.upsample_3x = self.Upsample3x(input_channels=input_channels)\n\n        # define the submodule that produces a feature map upsampled by 3x\n        self.upsample_4x = self.Upsample4x(input_channels=input_channels)\n\n    def forward(self, h_fm, scale: int):\n        # feed the input tensor to one of the upsamplers according to the given scale\n        if scale == 2:\n            upsampled = self.upsample_2x(h_fm)\n        elif scale == 3:\n            upsampled = self.upsample_3x(h_fm)\n        elif scale == 4:\n            upsampled = self.upsample_4x(h_fm)\n        else:\n            raise Exception(f\"Scale factor {scale} is invalid, select between 2, 3 or 4\")\n\n        return upsampled\n\n\nclass MultiPathResidualNetwork(nn.Module):\n    def __init__(self, input_channels: int, n_features: int = 64):\n        super().__init__()\n\n        # initialize initial shallow feature extractor\n        kernel_size = 3\n        padding_size = kernel_size // 2\n        self.sfe = nn.Conv2d(in_channels=input_channels, out_channels=n_features, kernel_size=(3, 3),\n                             padding=padding_size)\n\n        # define the Residual Module\n        self.rm = ResidualModule(input_channels=n_features)\n\n        # define the Feature Module\n        self.fm = FeatureModule(input_channels=n_features)\n\n        # define teh UpNet Module\n        self.upnet = UpNetModule(input_channels=n_features)\n\n        # define the final 3x3 convolution that restores the channels to three RGB channels\n        self.out_conv = nn.Conv2d(in_channels=n_features, out_channels=input_channels, kernel_size=(3, 3),\n                                  padding=padding_size)\n\n    def forward(self, lrs, scale: int):\n        # input is the batch of low resolution images, with shape (N, 3, 64, 64)\n        h_sfe = self.sfe(lrs)  # output size (N, 64, 64, 64)\n\n        # feed h_sfe to the residual module\n        h_rm = self.rm(h_sfe)  # output size (N, 64, 64, 64)\n\n        # feed h_rm and h_sfe to the feature module\n        h_fm = self.fm(h_rm, h_sfe)  # output size (N, 64, 64, 64)\n\n        # feed h_fm to the upnet module\n        upscaled_fm = self.upnet(h_fm, scale)  # output size (N, 64, 64 * scale, 64 * scale)\n\n        # feed upscaled feature map to the last 3x3 conv layer to get the final hr image in 3 RGB channels\n        srs = self.out_conv(upscaled_fm)  # output size (N, 3,  64 * scale, 64 * scale)\n\n        return srs","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:22.805380Z","iopub.execute_input":"2024-12-15T12:38:22.805700Z","iopub.status.idle":"2024-12-15T12:38:22.848952Z","shell.execute_reply.started":"2024-12-15T12:38:22.805667Z","shell.execute_reply":"2024-12-15T12:38:22.848043Z"},"papermill":{"duration":0.04756,"end_time":"2024-12-14T09:30:43.882103","exception":false,"start_time":"2024-12-14T09:30:43.834543","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"433f16af","cell_type":"code","source":"from torch.nn import DataParallel\n\n\n# Create the model\nmodel = MultiPathResidualNetwork(input_channels=3, n_features=128).to(\"cuda\")\n\nmodel = DataParallel(model)\n\n\n# Test input\n# lrs = torch.randn(1, 3, 160,160).to(\"cuda\")  # Batch of 2 images, 3 channels, 64x64 resolution\nlrs = torch.randn(1,3,160,256)\nscale = 4\n\n# Forward pass\nwith torch.no_grad():\n    srs = model(lrs, scale)\n\nprint(\"Input shape:\", lrs.shape)\nprint(\"Output shape:\", srs.shape)\nassert srs.shape == (1, 3, 160 * scale, 256 * scale), \"Output shape is incorrect!\"","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:22.850071Z","iopub.execute_input":"2024-12-15T12:38:22.850469Z","iopub.status.idle":"2024-12-15T12:38:23.838305Z","shell.execute_reply.started":"2024-12-15T12:38:22.850395Z","shell.execute_reply":"2024-12-15T12:38:23.837281Z"},"papermill":{"duration":2.195841,"end_time":"2024-12-14T09:30:46.081215","exception":false,"start_time":"2024-12-14T09:30:43.885374","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Input shape: torch.Size([1, 3, 160, 256])\nOutput shape: torch.Size([1, 3, 640, 1024])\n","output_type":"stream"}],"execution_count":9},{"id":"08513871","cell_type":"code","source":"from torchmetrics import PeakSignalNoiseRatio\n\ndef train_one_epoch(model, train_loader, criterion, psnr_metric, optimizer, device):\n\n    model.train()\n    total_loss = 0.0\n    total_psnr = 0.0\n    \n    progress_bar = tqdm(train_loader, desc='Training', unit='batch')\n    for lr_images, hr_images in progress_bar:\n        # Move data to the correct device\n        lr_images = lr_images.to(device)\n        hr_images = hr_images.to(device)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        sr_images = model(lrs=lr_images, scale=4)\n        \n        # Calculate loss\n        loss = criterion(sr_images, hr_images)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        # Calculate PSNR for monitoring\n        batch_psnr = psnr_metric(sr_images, hr_images).mean().item()\n        \n        # Update progress bar and tracking metrics\n        total_loss += loss.item()\n        total_psnr += batch_psnr\n        progress_bar.set_postfix({\n            'Loss': f'{loss.item():.4f}', \n            'PSNR': f'{batch_psnr:.2f}'\n        })\n    \n    # Return average loss and PSNR for the epoch\n    return total_loss / len(train_loader), total_psnr / len(train_loader)\n\n\n\ndef validate(model, val_loader, criterion, psnr_metric, device):\n\n    model.eval()\n    total_loss = 0.0\n    total_psnr = 0.0\n    \n    progress_bar = tqdm(val_loader, desc='Validation', unit='batch')\n    with torch.no_grad():\n        for lr_images, hr_images in progress_bar:\n            # Move data to the correct device\n            lr_images = lr_images.to(device)\n            hr_images = hr_images.to(device)\n            \n            # Forward pass\n            sr_images = model(lrs=lr_images, scale=4)\n            \n            # Calculate loss\n            loss = criterion(sr_images, hr_images)\n            \n            # Calculate PSNR for monitoring\n            batch_psnr = psnr_metric(sr_images, hr_images).mean().item()\n            \n            # Update tracking metrics\n            total_loss += loss.item()\n            total_psnr += batch_psnr\n            \n            progress_bar.set_postfix({\n                'Loss': f'{loss.item():.4f}', \n                'PSNR': f'{batch_psnr:.2f}'\n            })\n    \n    # Return average loss and PSNR for validation\n    return total_loss / len(val_loader), total_psnr / len(val_loader)\n\ndef train_super_resolution_model(\n    model, \n    train_loader, \n    val_loader, \n    num_epochs=3, \n    learning_rate=1e-4, \n    weight_decay=1e-5,\n    checkpoint_path=\"best_model.pth\"\n):\n\n    # Ensure model is on CUDA\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    \n    # Loss function (typically L1 or L2 loss for image reconstruction)\n    criterion = nn.MSELoss()\n    \n    # PSNR metric\n    psnr_metric = PeakSignalNoiseRatio().to(device) # torchmetrics.image.PeakSignalNoiseRatio().to(device)\n    \n    # Optimizer with weight decay (L2 regularization)\n    optimizer = optim.Adam(\n        model.parameters(), \n        lr=learning_rate, \n        weight_decay=weight_decay\n    )\n    \n    # Learning rate scheduler (optional, but often helpful)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, \n        mode='min', \n        factor=0.5, \n        patience=5\n    )\n    \n    # Track best model\n    best_val_psnr = float('-inf')\n    best_epoch = 0\n    \n    # Training history\n    history = {\n        'train_loss': [],\n        'train_psnr': [],\n        'val_loss': [],\n        'val_psnr': []\n    }\n    \n    # Start training loop\n    for epoch in range(num_epochs):\n        print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n        \n        # Train the model for one epoch\n        train_loss, train_psnr = train_one_epoch(\n            model, train_loader, criterion, psnr_metric, optimizer, device\n        )\n        history['train_loss'].append(train_loss)\n        history['train_psnr'].append(train_psnr)\n        \n        # Validate the model\n        val_loss, val_psnr = validate(model, val_loader, criterion, psnr_metric, device)\n        history['val_loss'].append(val_loss)\n        history['val_psnr'].append(val_psnr)\n        \n        # Print the epoch stats\n        print(f\"Training Loss: {train_loss:.4f}, Training PSNR: {train_psnr:.2f}\")\n        print(f\"Validation Loss: {val_loss:.4f}, Validation PSNR: {val_psnr:.2f}\")\n        \n        # Update learning rate scheduler based on validation loss\n        scheduler.step(val_loss)\n\n        torch.cuda.empty_cache()\n        \n        # Save the best model (based on validation PSNR)\n        if val_psnr > best_val_psnr:\n            best_val_psnr = val_psnr\n            best_epoch = epoch\n            print(f\"New best model found, saving model at epoch {epoch+1}\")\n            torch.save(model.state_dict(), checkpoint_path)\n    \n    print(f\"\\nTraining completed. Best validation PSNR: {best_val_psnr:.2f} at epoch {best_epoch+1}\")\n    \n    # Return the training history\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:23.840783Z","iopub.execute_input":"2024-12-15T12:38:23.841081Z","iopub.status.idle":"2024-12-15T12:38:23.856535Z","shell.execute_reply.started":"2024-12-15T12:38:23.841052Z","shell.execute_reply":"2024-12-15T12:38:23.855639Z"},"papermill":{"duration":0.020231,"end_time":"2024-12-14T09:30:46.105198","exception":false,"start_time":"2024-12-14T09:30:46.084967","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"845a6002","cell_type":"code","source":"history = train_super_resolution_model(\n    model, train_loader, val_loader, num_epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-15T12:38:23.857528Z","iopub.execute_input":"2024-12-15T12:38:23.857830Z","iopub.status.idle":"2024-12-15T20:26:33.311712Z","shell.execute_reply.started":"2024-12-15T12:38:23.857805Z","shell.execute_reply":"2024-12-15T20:26:33.310641Z"},"papermill":{"duration":2966.414368,"end_time":"2024-12-14T10:20:12.522953","exception":false,"start_time":"2024-12-14T09:30:46.108585","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.\n  _future_warning(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch [1/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:20<00:00,  1.06batch/s, Loss=0.0007, PSNR=26.32]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=26.72]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0013, Training PSNR: 25.98\nValidation Loss: 0.0003, Validation PSNR: 25.84\nNew best model found, saving model at epoch 1\n\nEpoch [2/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.36]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.74]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.47\nValidation Loss: 0.0002, Validation PSNR: 26.74\nNew best model found, saving model at epoch 2\n\nEpoch [3/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0006, PSNR=26.87]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.71]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.84\nValidation Loss: 0.0002, Validation PSNR: 26.77\nNew best model found, saving model at epoch 3\n\nEpoch [4/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.14]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.81]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.92\nValidation Loss: 0.0002, Validation PSNR: 26.84\nNew best model found, saving model at epoch 4\n\nEpoch [5/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.83]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.85]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.96\nValidation Loss: 0.0002, Validation PSNR: 26.88\nNew best model found, saving model at epoch 5\n\nEpoch [6/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.79]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.83]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.97\nValidation Loss: 0.0002, Validation PSNR: 26.87\n\nEpoch [7/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.57]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=27.74]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.99\nValidation Loss: 0.0002, Validation PSNR: 26.80\n\nEpoch [8/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.95]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=27.60]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.96\nValidation Loss: 0.0002, Validation PSNR: 26.67\n\nEpoch [9/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.44]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=27.91]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.03\nValidation Loss: 0.0002, Validation PSNR: 26.94\nNew best model found, saving model at epoch 9\n\nEpoch [10/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.26]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.14]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.00\nValidation Loss: 0.0002, Validation PSNR: 27.12\nNew best model found, saving model at epoch 10\n\nEpoch [11/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.98]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.00]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.03\nValidation Loss: 0.0002, Validation PSNR: 27.02\n\nEpoch [12/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=28.96]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.66]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 28.97\nValidation Loss: 0.0002, Validation PSNR: 26.74\n\nEpoch [13/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.12]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=27.92]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.04\nValidation Loss: 0.0002, Validation PSNR: 26.95\n\nEpoch [14/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.58]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.99]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.01\nValidation Loss: 0.0002, Validation PSNR: 27.00\n\nEpoch [15/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.34]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.84]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.01\nValidation Loss: 0.0002, Validation PSNR: 26.91\n\nEpoch [16/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.68]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.00]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.05\nValidation Loss: 0.0002, Validation PSNR: 27.00\n\nEpoch [17/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0006, PSNR=26.84]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.97]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.08\nValidation Loss: 0.0002, Validation PSNR: 26.99\n\nEpoch [18/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0006, PSNR=26.82]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.04]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.08\nValidation Loss: 0.0002, Validation PSNR: 27.05\n\nEpoch [19/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.02]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.07\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [20/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.16]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.06]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.08\nValidation Loss: 0.0002, Validation PSNR: 27.07\n\nEpoch [21/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0006, PSNR=27.16]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=27.74]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.05\nValidation Loss: 0.0002, Validation PSNR: 26.80\n\nEpoch [22/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.04]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.00]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.07\nValidation Loss: 0.0002, Validation PSNR: 27.02\n\nEpoch [23/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.37]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.01]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.02\n\nEpoch [24/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=28.17]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.03]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.09\nValidation Loss: 0.0002, Validation PSNR: 27.04\n\nEpoch [25/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.13]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.05\n\nEpoch [26/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.65]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.11]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [27/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.37]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [28/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.22]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=27.81]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.09\nValidation Loss: 0.0002, Validation PSNR: 26.86\n\nEpoch [29/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.20]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.06]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.07\n\nEpoch [30/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.23]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.06]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [31/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.20]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.06]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.06\n\nEpoch [32/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.66]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [33/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.24]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.07\n\nEpoch [34/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=28.54]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.01]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.01\n\nEpoch [35/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.62]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.11]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.10\n\nEpoch [36/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.16]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.05]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.06\n\nEpoch [37/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.05]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.12]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.11\n\nEpoch [38/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.72]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [39/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.41]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.10]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [40/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.87]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.06]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.06\n\nEpoch [41/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.57]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.05]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.06\n\nEpoch [42/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.82]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.03]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.05\n\nEpoch [43/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.69]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.10]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [44/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=28.95]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [45/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0007, PSNR=26.50]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.10\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [46/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.73]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.01]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.02\n\nEpoch [47/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.12]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.10]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.10\n\nEpoch [48/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0006, PSNR=27.19]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.05]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.05\n\nEpoch [49/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.02]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [50/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.67]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.04]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.06\n\nEpoch [51/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.33]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [52/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.66]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [53/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.26]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [54/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=32.07]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.10]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.10\n\nEpoch [55/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.45]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.10]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.10\n\nEpoch [56/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.81]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.07\n\nEpoch [57/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.51]\nValidation: 100%|██████████| 67/67 [00:19<00:00,  3.52batch/s, Loss=0.0002, PSNR=28.06]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.06\n\nEpoch [58/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.53]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [59/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.53]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [60/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0001, PSNR=29.76]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.07\n\nEpoch [61/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.51]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [62/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.10]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [63/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0006, PSNR=27.06]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [64/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.02]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [65/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.09]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [66/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.48]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [67/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.03]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [68/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.95]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [69/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.80]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [70/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.00]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [71/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.77]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [72/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0007, PSNR=26.17]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [73/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.51]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [74/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.49]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [75/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.57]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.07\n\nEpoch [76/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.09]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.09]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [77/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=29.16]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [78/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.80]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [79/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.53]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [80/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.46]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.07]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [81/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.65]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.09\n\nEpoch [82/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.83]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [83/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.28]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [84/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=28.58]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [85/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.13]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [86/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.93]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [87/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=28.11]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [88/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.64]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [89/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.64]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [90/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.81]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [91/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.19]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [92/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0006, PSNR=26.73]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [93/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0005, PSNR=27.32]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [94/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.77]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [95/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.21]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.11\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [96/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.21]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [97/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=29.86]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [98/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0002, PSNR=31.01]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [99/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0004, PSNR=29.14]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nEpoch [100/100]\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 277/277 [04:21<00:00,  1.06batch/s, Loss=0.0003, PSNR=30.69]\nValidation: 100%|██████████| 67/67 [00:18<00:00,  3.53batch/s, Loss=0.0002, PSNR=28.08]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0004, Training PSNR: 29.12\nValidation Loss: 0.0002, Validation PSNR: 27.08\n\nTraining completed. Best validation PSNR: 27.12 at epoch 10\n","output_type":"stream"}],"execution_count":11},{"id":"3e884409","cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\nimport torchvision.utils as vutils\nfrom tqdm import tqdm\n\ndef process_and_save_images(model, input_folder, output_folder, device):\n\n    # Create output folder if it does not exist\n    os.makedirs(output_folder, exist_ok=True)\n\n    # Get list of image files in the input folder\n    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\n    # Ensure the model is in evaluation mode\n    model.eval()\n\n    # Apply the image transformation to each image in the input folder with tqdm for progress bar\n    for image_file in tqdm(image_files, desc=\"Processing images\", unit=\"image\"):\n        image_path = os.path.join(input_folder, image_file)\n        output_path = os.path.join(output_folder, image_file)\n\n        # Open the image\n        image = Image.open(image_path).convert('RGB')\n        # image = Image.open(image_path).convert(\"L\")\n\n        # Apply the predefined image transformation\n        transformed_image = image_transform(image).unsqueeze(0).to(device)\n\n        # Send the image through the model to get the super-resolved image\n        with torch.no_grad():\n            sr_image = model(lrs=transformed_image, scale=4)  # Use your model's method\n\n        # Convert the output image to CPU and denormalize if necessary (depending on how the model was trained)\n        sr_image = sr_image.squeeze(0).cpu()\n        \n        # Assuming the output is a tensor, save it as an image\n        vutils.save_image(sr_image, output_path)\n\n        # Print message after saving\n        # tqdm.write(f\"Saved super-resolved image to {output_path}\")\n\n# Example usage\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Assume `model` is already defined and loaded with weights\nprocess_and_save_images(model, \"/kaggle/input/enhance-the-dark-world/archive/test\", \"/kaggle/working/output\", device)","metadata":{"execution":{"iopub.status.busy":"2024-12-15T20:26:33.313604Z","iopub.execute_input":"2024-12-15T20:26:33.313965Z","iopub.status.idle":"2024-12-15T20:26:59.169169Z","shell.execute_reply.started":"2024-12-15T20:26:33.313931Z","shell.execute_reply":"2024-12-15T20:26:59.168331Z"},"papermill":{"duration":31.575607,"end_time":"2024-12-14T10:20:44.405809","exception":false,"start_time":"2024-12-14T10:20:12.830202","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"Processing images: 100%|██████████| 60/60 [00:25<00:00,  2.32image/s]\n","output_type":"stream"}],"execution_count":12},{"id":"9d369290","cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\ndef images_to_csv(folder_path, output_csv):\n    data_rows = []\n    for filename in sorted(os.listdir(folder_path)):\n        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L') \n            image_array = np.array(image).flatten()[::8]\n            data_rows.append([\"gt\"+filename.split('.')[0][4:], *image_array])\n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')\n\nfolder_path = '/kaggle/working/output'\noutput_csv = 'submission.csv'\nimages_to_csv(folder_path, output_csv)","metadata":{"execution":{"iopub.status.busy":"2024-12-15T20:26:59.170419Z","iopub.execute_input":"2024-12-15T20:26:59.170773Z","iopub.status.idle":"2024-12-15T20:27:41.572702Z","shell.execute_reply.started":"2024-12-15T20:26:59.170734Z","shell.execute_reply":"2024-12-15T20:27:41.571786Z"},"papermill":{"duration":44.710881,"end_time":"2024-12-14T10:21:29.424630","exception":false,"start_time":"2024-12-14T10:20:44.713749","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Successfully saved to submission.csv\n","output_type":"stream"}],"execution_count":13},{"id":"4c443e37","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.302826,"end_time":"2024-12-14T10:21:30.038604","exception":false,"start_time":"2024-12-14T10:21:29.735778","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}